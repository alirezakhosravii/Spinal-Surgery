import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import GridSearchCV

# Generate synthetic data
np.random.seed(42)
n_samples = 1000
age = np.random.randint(20, 80, n_samples)
gender = np.random.choice(['Male', 'Female'], n_samples)
preoperative_pain_level = np.random.uniform(1, 10, n_samples)
spinal_condition = np.random.choice(['Degenerative Disc Disease', 'Spinal Stenosis', 'Scoliosis'], n_samples)
surgical_technique = np.random.choice(['PLIF', 'ALIF', 'TLIF'], n_samples)
bone_density = np.random.uniform(0.8, 1.5, n_samples)
num_vertebrae_fused = np.random.randint(1, 4, n_samples)
smoking_status = np.random.choice(['Smoker', 'Non-Smoker'], n_samples)
bmi = np.random.uniform(18, 35, n_samples)

# Generate prognosis based on simplistic rules
prognosis = []
for i in range(n_samples):
    success_prob = 0.5
    if age[i] < 40:
        success_prob += 0.1
    if preoperative_pain_level[i] < 5:
        success_prob += 0.1
    if bone_density[i] > 1:
        success_prob += 0.1
    if num_vertebrae_fused[i] == 1:
        success_prob += 0.1
    if smoking_status[i] == 'Non-Smoker':
        success_prob += 0.1
    prognosis.append('Successful' if np.random.rand() < success_prob else 'Unsuccessful')

# Create DataFrame
data = pd.DataFrame({
    'Age': age,
    'Gender': gender,
    'Preoperative_Pain_Level': preoperative_pain_level,
    'Spinal_Condition': spinal_condition,
    'Surgical_Technique': surgical_technique,
    'Bone_Density': bone_density,
    'Num_Vertebrate_Fused': num_vertebrae_fused,
    'Smoking_Status': smoking_status,
    'BMI': bmi,
    'Prognosis': prognosis
})

# Preprocessing
cat_features = ['Gender', 'Spinal_Condition', 'Surgical_Technique', 'Smoking_Status']
cont_features = ['Age', 'Preoperative_Pain_Level', 'Bone_Density', 'Num_Vertebrate_Fused', 'BMI']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), cont_features),
        ('cat', OneHotEncoder(), cat_features)])

# Split data
X = data.drop('Prognosis', axis=1)
y = data['Prognosis']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Model training and hyperparameter tuning
pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('classifier', SVC())])
param_grid = {'classifier__C': [0.1, 1, 10], 'classifier__gamma': [0.001, 0.01, 0.1, 1]}
grid_search = GridSearchCV(pipeline, param_grid, cv=5)
grid_search.fit(X_train, y_train)

# Model evaluation
y_pred = grid_search.predict(X_test)
test_accuracy = accuracy_score(y_test, y_pred)
classification_rep = classification_report(y_test, y_pred)

print("Best Parameters:", grid_search.best_params_)
print("Cross-validation Accuracy:", grid_search.best_score_)
print("Test Set Accuracy:", test_accuracy)
print("Classification Report:", classification_rep)
